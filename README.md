# AI2026
# ğŸ¤– AI Assistant (v1.0)

A desktop AI Assistant built using **Electron + Python** with a **free, offline Large Language Model (LLM)**.  
The assistant runs locally on your machine, supports **voice responses**, and does **not require any paid APIs**.

This is **Version 1**, focused on a clean working foundation.  
More features are planned and under development.

---

## âœ¨ Features (v1)

- ğŸ–¥ï¸ Desktop application (Electron)
- ğŸ§  Offline AI (no internet required after setup)
- ğŸ’¬ Text-based chat interface
- ğŸ”Š Voice responses (Text-to-Speech)
- ğŸ”‡ Voice ON / OFF toggle
- âš¡ Fast local inference using Ollama
- ğŸš€ Single command startup (`npm start`)
- ğŸ§ª Easy to modify and extend

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Electron**
- HTML, CSS, JavaScript

### Backend
- **Python**
- FastAPI

### AI / LLM
- **Ollama**
- **LLaMA 3** (local LLM model)

---

## ğŸ§  LLM Model Used

- **Model:** `llama3`
- **Provider:** Ollama (local runtime)
- **Type:** Offline, on-device Large Language Model

No OpenAI or paid APIs are used.

---

## ğŸ“¦ Requirements (Before Running)

Make sure the following are installed on your system:

### 1ï¸âƒ£ Node.js (v18+ recommended)
```bash
node -v
npm -v
2ï¸âƒ£ Python (3.9+)
python --version
 Python (3.9+)
python --version
3ï¸âƒ£ Ollama (Required for AI)
Download and install from:
from: https://ollama.com
download llm model:
>ollama pull llama3

##Project structure

AI2026/
â”‚
â”œâ”€â”€ app/                # Electron frontend (HTML/CSS/JS)
â”œâ”€â”€ backend/            # Python backend (FastAPI)
â”‚   â””â”€â”€ ai/llm.py       # Ollama integration
â”œâ”€â”€ electron/           # Electron main process
â”œâ”€â”€ .venv/              # Python virtual environment
â”œâ”€â”€ package.json
â””â”€â”€ README.md


ğŸš€ How to Run (Single Command)
1ï¸âƒ£ Install dependencies
npm install
2ï¸âƒ£ Start the app
npm start
This single command:
Starts the Python backend
Launches the Electron app
Connects to the local AI automatically
No manual terminal setup required


##ğŸ”Š Voice Controls
ğŸ”Š Speaker button â†’ Enable voice response
ğŸ”‡ Mute button â†’ Disable voice response instantly
Voice uses system Text-to-Speech (macOS supported)


##ğŸ§ª Current Version
v1.0
Stable local AI assistant
Offline support
Voice output
Clean dev workflow
ğŸš§ Next Version (In Development)
Planned features for upcoming versions:
ğŸ§  Conversation memory
ğŸ™ Voice input (talk to the AI)
ğŸ¤– Improved AI personality
ğŸ“¦ Packaged .dmg / .exe installers
ğŸ¨ UI polish and animations
âš™ï¸ Auto-detection / bundling of Ollama


###ğŸ“ Notes
Ollama must remain installed on the system for AI responses.
This project is intended for learning, experimentation, and extension.
Architecture is modular and easy to upgrade.

ğŸ“œ License
This project is currently for educational and personal use.
License can be added later if needed.
ğŸ™Œ Acknowledgements
Ollama for local LLM runtime
Meta for LLaMA models
Electron & FastAPI communities

